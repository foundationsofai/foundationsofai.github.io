<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Foundations of AI Seminar Series | Georgia Tech</title>
    <style>
        body, html {
            margin: 0;
            padding: 0;
            font-family: 'Arial', sans-serif;
            color: #333;
            overflow-x: hidden;
            background-color: white; /* Change background to white */
        }
        .banner {
            width: 100%;
            height: 300px;
            background-image: url('background.jpg'); /* Use background.jpg here */
            background-size: cover;
            background-position: center;
            margin-bottom: 30px;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: rgba(255, 255, 255, 0.8); /* Add semi-transparent white background */
        }
        header {
            text-align: center;
            padding: 50px 0;
        }
        h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            color: #003057;
        }
        h2 {
            font-size: 1.5em;
            color: #B3A369;
            margin-bottom: 20px;
        }
        .intro {
            background-color: rgba(255, 255, 255, 0.8);
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 30px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        .schedule {
            background-color: #f8f8f8;
            padding: 30px;
            border-radius: 15px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        .schedule h3 {
            color: #003057;
            font-size: 2em;
            text-align: center;
            margin-bottom: 30px;
            border-bottom: 2px solid #B3A369;
            padding-bottom: 10px;
        }
        .schedule ul {
            list-style-type: none;
            padding: 0;
        }
        .schedule li {
            background-color: #fff;
            border-radius: 10px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            padding: 25px;
            margin-bottom: 30px;
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }
        .schedule li:hover {
            transform: translateY(-5px);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.15);
        }
        .schedule .speaker,
        .schedule .affiliation,
        .schedule .date-time,
        .schedule .location,
        .schedule .topic {
            font-size: 1.2em;
            margin-bottom: 10px;
            display: block;
        }
        .schedule .speaker {
            font-size: 1.8em;
            font-weight: bold;
            color: #003057;
        }
        .schedule .affiliation {
            color: #666;
            /* Remove the italic style */
            font-style: normal;
        }
        .schedule .date-time,
        .schedule .location {
            background-color: #B3A369;
            color: white;
            padding: 5px 10px;
            border-radius: 5px;
            display: inline-block;
        }
        .schedule .location a {
            color: white;
            text-decoration: none;
            transition: color 0.3s ease;
        }
        .schedule .location a:hover {
            color: #003057;
            text-decoration: underline;
        }
        .schedule .topic {
            font-weight: bold;
            color: #003057;
            margin-top: 15px;
        }
        .schedule .abstract, .schedule .bio {
            margin-top: 20px;
            line-height: 1.6;
            text-align: justify;
        }
        .schedule .abstract-title, .schedule .bio-title {
            font-weight: bold;
            color: #003057;
            margin-bottom: 10px;
            display: block;
            font-size: 1.2em;
            border-bottom: 1px solid #B3A369;
            padding-bottom: 5px;
        }
        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }
        .fade-in {
            animation: fadeIn 1s ease-in;
        }
        #mc_embed_signup {
            background-color: rgba(255, 255, 255, 0.8);
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            margin-top: 30px;
        }
        #mc_embed_signup h3 {
            color: #003057;
            margin-bottom: 20px;
        }
        #mc_embed_signup .mc-field-group {
            margin-bottom: 15px;
        }
        #mc_embed_signup .button {
            background-color: #B3A369;
            color: white;
            border: none;
            padding: 10px 20px;
            border-radius: 5px;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        #mc_embed_signup .button:hover {
            background-color: #003057;
        }
        .schedule .emoji {
            margin-right: 10px;
            font-size: 1.2em;
        }
        .organizers {
            background-color: #f8f8f8;
            padding: 30px;
            border-radius: 15px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            margin-top: 30px;
        }

        .organizers h3 {
            color: #003057;
            font-size: 2em;
            text-align: center;
            margin-bottom: 30px;
            border-bottom: 2px solid #B3A369;
            padding-bottom: 10px;
        }

        .organizer-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 30px;
        }

        .organizer {
            background-color: #fff;
            border-radius: 10px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            padding: 25px;
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }

        .organizer:hover {
            transform: translateY(-5px);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.15);
        }

        .organizer h4 {
            color: #003057;
            font-size: 1.5em;
            margin-bottom: 10px;
        }

        .organizer .title {
            color: #B3A369;
            font-weight: bold;
            margin-bottom: 10px;
        }

        .organizer a {
            color: #003057;
            text-decoration: none;
            transition: color 0.3s ease;
        }

        .organizer a:hover {
            color: #B3A369;
            text-decoration: underline;
        }

        .organizer .research-areas {
            margin-top: 15px;
            font-style: italic;
            color: #666;
        }

        .tabs {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }

        .tab-button {
            background-color: #f1f1f1;
            border: none;
            outline: none;
            cursor: pointer;
            padding: 14px 16px;
            transition: 0.3s;
            font-size: 17px;
            border-radius: 5px 5px 0 0;
            margin: 0 5px;
        }

        .tab-button:hover {
            background-color: #ddd;
        }

        .tab-button.active {
            background-color: #B3A369;
            color: white;
        }

        .tab-content {
            display: none;
            padding: 6px 12px;
            border-top: none;
        }

        .tab-content.active {
            display: block;
        }

        .student-button {
            display: block;
            width: 200px;
            margin: 30px auto;
            padding: 15px 20px;
            background-color: #B3A369;
            color: white;
            text-align: center;
            text-decoration: none;
            font-size: 1.2em;
            border-radius: 5px;
            transition: background-color 0.3s ease;
        }

        .student-button:hover {
            background-color: #003057;
        }

        .sponsorship {
            text-align: center;
            margin-top: 30px;
            padding: 20px;
            background-color: #f8f8f8;
            border-radius: 10px;
        }

        .sponsorship img {
            max-width: 300px; /* Increase the size of the image */
            vertical-align: middle; /* Align the image with the text */
            margin-right: 10px; /* Space between the image and text */
        }

        .sponsorship a {
            color: #003057;
            text-decoration: none;
            transition: color 0.3s ease;
        }

        .sponsorship a:hover {
            color: #B3A369;
            text-decoration: underline;
        }

        .speaker-info {
            display: flex;
            gap: 20px;
            align-items: flex-start;
            margin-top: 20px;
        }

        .speaker-image {
            width: 200px;
            height: 200px;
            object-fit: cover;
            border-radius: 10px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }

        .speaker-text {
            flex: 1;
        }
    </style>
</head>
<body>
    <div class="banner"></div>
    <div class="container">
        <!-- Add the sponsorship section at the top -->
        <div class="sponsorship fade-in">
            <img src="IDEaS.png" alt="IDEaS Logo"> <!-- Include the IDEaS logo -->
            <p>
                Sponsored by <a href="https://research.gatech.edu/energy/ideas" target="_blank">The Institute for Data Engineering and Science (IDEaS)</a>.<br>
                Supported by the <a href="https://www.scs.gatech.edu/" target="_blank">School of Computer Science</a>.
            </p>
        </div>

        <header class="fade-in">
            <h1>Foundations of Artificial Intelligence Seminar Series</h1>
            <h2>by Foundations of Artificial Intelligence @ Georgia Institute of Technology</h2>
        </header>
        <div class="intro fade-in">
            <p>Welcome to the AI Seminar Series @ Georgia Tech, a seminar showcasing the latest research and developments in Artificial Intelligence. Our goal is to bring together students, postdocs, professors, and industry researchers to discuss a wide range of AI topics, including Machine Learning, Efficient AI, Symbolic AI, AI Theory, AI Systems, and the intersection of AI and Programming Languages and Software Engineering (PLSE).</p>
        </div>

        <div class="schedule fade-in">
            <h3>Speaker Schedule and Abstracts</h3>
            
            <h4 style="color: #003057; margin: 30px 0 20px;">Future Talks</h4>
             <ul>
                <li>
                    <span class="speaker"><span class="emoji">🎤</span><a href="Website: https://www.cc.gatech.edu/people/irfan-essa/" target="_blank">Irfan Essa</a></span>
                    <span class="affiliation"><span class="emoji">🏛️</span>School of Interactive Computing, Georgia Institute of Technology</span>
                    <span class="date-time"><span class="emoji">📅</span>Tuesday, October 7, 2025 | 12:00 PM - 1:00 PM (ET)</span>
                    <span class="location">
                        <span class="emoji">📍</span> CODA Building 9th floor Atrium | 
                        <span class="emoji">💻</span><a href="https://gatech.zoom.us/j/99776563764?pwd=lqx6UuqGbG6TrIlGSbq6WPshZc0ibT.1" target="_blank">Zoom</a>
                    </span>
                    <span class="topic"><span class="emoji">📚</span>Wizard of Oz at the Sphere</span>
                    <div class="abstract">
                        <span class="abstract-title"><span class="emoji">📝</span>Abstract</span>
In the classic 1939 film The Wizard of Oz, Dorothy travels from Kansas to Oz. Using the wizardry of Google AI, Dorothy and her friends now are visiting the Sphere in Las Vegas for an immersive and experiential retelling of their story! 

In partnership with Sphere Inc., Warner Bros. Magnopus, teams from GDM and Google Cloud have reimagined "The Wizard of Oz" as an immersive experience for the Sphere, an enormous (yes) sphere-shaped venue that seats more than 17,000 people. A traditional movie experience it is not.

In this talk, I will present details of this project, first announced at Google Cloud Next '25, The goal was to use AI to augment the work of VFX artists, elevating the visual content of the 1939 classic for Sphere's one-of-a-kind display all while honoring the original story. To tackle the unique challenges of enhancing and scaling this classic film for the world's largest screen, our teams developed new AI capabilities, including:
    1) Veo driven fine-tuning for character performance to ensure that beloved characters' movements remained authentic.
    2) AI-powered super-resolution to upscale classic footage to an unprecedented scale.
    3) Outpainting to extend characters and foreground elements beyond the boundary of the original film, which is limited in scale and aspect ratio.

Google teams developed novel AI techniques, to bring a classic film from a cinematic to an experiential medium and provided technologies to artists to create a truly special 75 minute movie + experience through care and commitment to craft, storytelling, and authenticity. This project involved working with over a thousand artists, researchers and engineers to create a new form of entertainment and a landmark effort in the history of entertainment that will be running in Las Vegas for a long time.                    <div class="bio">
                        <span class="bio-title"><span class="emoji">👤</span>Bio</span>
                        <div class="speaker-info">
                            <img src="irfan_essa_0.png" alt="Dr. Irfan Essa" class="speaker-image">
                            <div class="speaker-text">
Irfan Essa is a Distinguished Professor in the School of Interactive Computing (iC) and a Senior Associate Dean in the College of Computing (CoC), at the Georgia Institute of Technology (GA Tech), in Atlanta, Georgia, USA. He is serving as the Inaugural Executive Director of the new Interdisciplinary Research Center for Machine Learning at Georgia Tech (ML@GT). He also serves as a Senior Staff Research Scientist at Google Inc. Professor Essa works in the areas of Computer Vision, Machine Learning, Computer Graphics, Computational Perception, Robotics, Computer Animation, and Social Computing, with potential impact on Autonomous Systems, Video Analysis, and Production (e.g., Computational Photography & Video, Image-based Modeling and Rendering, etc.) Human Computer Interaction, Artificial Intelligence, Computational Behavioral/Social Sciences, and Computational Journalism research.  He has published over 200 scholarly articles in leading journals and conference venues on these topics and several of his papers have also won best paper awards. He has been awarded the NSF CAREER  and was elected to the grade of IEEE Fellow. He has held extended research consulting positions with Disney Research and Google Research and also was an Adjunct Faculty Member at Carnegie Mellon’s Robotics Institute.  He joined GA Tech Faculty in 1996 after his earning his MS (1990), Ph.D. (1994), and holding research faculty position at the Massachusetts Institute of Technology (Media Lab) [1988-1996].                        </div>
                    </div>
                </li>
             </ul>

            <h4 style="color: #003057; margin: 30px 0 20px;">Past Talks</h4>
                         <ul>
                <li>
                    <span class="speaker"><span class="emoji">🎤</span><a href="Website: https://sarhadi.eas.gatech.edu/" target="_blank">Ali Sarhadi</a></span>
                    <span class="affiliation"><span class="emoji">🏛️</span>School of Earth and Atmospheric Sciences, Georgia Institute of Technology</span>
                    <span class="date-time"><span class="emoji">📅</span>Monday, September 22nd, 2025 | 12:00 PM - 1:00 PM (ET)</span>
                    <span class="location">
                        <span class="emoji">📍</span> Classroom 320 Cherry Emerson | 
                        <span class="emoji">💻</span><a href="https://gatech.zoom.us/j/93802422079" target="_blank">Zoom</a>
                    </span>
                    <span class="topic"><span class="emoji">📚</span>Physics-Informed Machine Learning for Climate Risk</span>
                    <div class="abstract">
                        <span class="abstract-title"><span class="emoji">📝</span>Abstract</span>
As climate change accelerates, the threat from compound weather and climate extremes—events in which multiple hazards interact to produce disproportionately large and often unpredictable impacts—is rapidly growing. This talk explores how AI techniques—including probabilistic graphical models, physics-informed machine learning, and generative AI—can effectively characterize and predict the evolving dynamics of these complex events under a nonstationary, warming climate, with an emphasis on hurricane-driven compound hazards. By embedding physical constraints into data-driven models, we develop scientifically grounded, scalable, and generalizable tools to assess emerging risks and inform adaptive strategies that enhance resilience in the face of escalating climate extremes.                    </div>
                    <div class="bio">
                        <span class="bio-title"><span class="emoji">👤</span>Bio</span>
                        <div class="speaker-info">
                            <img src="203.jpeg" alt="Dr. Ali Sarhadi" class="speaker-image">
                            <div class="speaker-text">
Ali Sarhadi is an Assistant Professor in the School of Earth and Atmospheric Sciences at the Georgia Institute of Technology, where he leads the Climate Risk & Extremes Dynamics Lab. His research focuses on climate extremes, compound and cascading hazards, and the integration of physics-informed artificial intelligence to assess and mitigate climate risks in a warming world. Dr. Sarhadi develops high-resolution simulations, physics-based models, and machine learning and climate AI tools to study tropical cyclones and their associated hazards, and to quantify their drivers, dynamics, and impacts on coastal communities and                             </div>
                        </div>
                    </div>
                </li>
             </ul>
                       <ul>
                <li>
                    <span class="speaker"><span class="emoji">🎤</span><a href="https://balsillieschool.ca/people/ann-fitz-gerald/" target="_blank">Ann Fitz-Gerald</a></span>
                    <span class="affiliation"><span class="emoji">🏛️</span>Balsillie School of International Affairs</span>
                    <span class="date-time"><span class="emoji">📅</span>Monday, September 8th, 2025 | 4:00 PM - 5:00 PM (ET)</span>
                    <span class="location">
                        <span class="emoji">📍</span>215 Classroom Instructional Center | 
                        <span class="emoji">💻</span><a href="https://gatech.zoom.us/j/93881550483" target="_blank">Zoom</a>
                    </span>
                    <span class="topic"><span class="emoji">📚</span>Talk Title: AI, new national security threat vectors, and ungoverned space</span>
                    <div class="abstract">
                        <span class="abstract-title"><span class="emoji">📝</span>Abstract</span>
                        Artificial intelligence is part of a broader “general-purpose” technology ecosystem that is transforming global security. Alongside AI, new threat vectors are emerging—from the growing role of non-state actors to the expansion of national security domains beyond land, sea, and air to include cyber and space. For middle powers, this landscape is further complicated by patchwork regulatory frameworks and the dominance of rules set by global powers. At the same time, the distinction between economic security and national security is rapidly dissolving, raising urgent questions about resilience, sovereignty, and competitiveness. This talk will explore what these shifts mean for the national capacity of governments, the role of civil servants, and the need to reimagine defence and security institutions in a digital era.
                    </div>
                    <div class="bio">
                        <span class="bio-title"><span class="emoji">👤</span>Bio</span>
                        <div class="speaker-info">
                            <img src="ann-fitz-gerald.jpg" alt="Dr. Ann Fitz-Gerald" class="speaker-image">
                            <div class="speaker-text">
                                Professor Ann Fitz-Gerald is the Director of the Balsillie School of International Affairs since August 2019 and has led the School’s “Technology Governance Initiative” since 2023. She has degrees in both commerce and political science from Queen’s University and was the first civilian female to graduate from the Royal Military College of Canada. Before completing a PhD in the UK, she worked at the Pearson Peacekeeping Centre, NATO headquarters, and the North Atlantic Assembly. She has worked as an academic at King’s College, London University and Cranfield University, where, before her move back to Canada, she was Director, Defence and Security Leadership at Cranfield’s Defence Academy of the United Kingdom campus. Ann is a Senior Research Fellow at the Royal United Services Institute, a Senior Fellow at the Institute for Peace and Diplomacy, a Fellow at McLaughlin College, York University and has served/still serves on a number of non-executive boards and in advisory roles for the British Government, the United Nations and the African Union. Ann is widely published on issues concerning the governance of national security and has helped facilitate national security policies and strategies in a number of conflict-affected countries including Afghanistan, Ethiopia, Sudan, Ukraine, Sierra Leone, Nepal, Serbia, Nigeria and others. She provides regular media commentary for both national and international broadcast media. She has also been appointed by organizations such as the United Nations, the African Union and the British Government to support internationally-sponsored peace talks, including the Sudan-South Sudan peace talks led by former South African President Thabo Mbeki – efforts for which the Government of Canada awarded Ann with the Queen’s Diamond Jubilee Medal.  In December 2024, Ann was recognized for her ongoing research on defence and national security and for her leadership of the Balsillie School of International Affairs and awarded the King Charles III Coronation Medal.
                            </div>
                        </div>
                    </div>
                </li>
             </ul>
            <ul>
                <li>
                    <span class="speaker"><span class="emoji">🎤</span><a href="https://sites.cc.gatech.edu/fac/constantinos.dovrolis/" target="_blank">Constantinos Dovrolis</a></span>
                    <span class="affiliation"><span class="emoji">🏛️</span>School of Computer Science, Georgia Tech</span>
                    <span class="date-time"><span class="emoji">📅</span>Thursday, May 1st, 2025 | 1:00 PM - 2:00 PM (ET)</span>
                    <span class="location">
                        <span class="emoji">📍</span>2456 Classroom, Klaus | 
                        <span class="emoji">💻</span><a href="https://gatech.zoom.us/j/93893335950" target="_blank">Zoom</a>
                    </span>
                    <span class="topic"><span class="emoji">📚</span>Talk Title: Sparsity, Modularity, and Plasticity in Deep Neural Networks</span>
                    <div class="abstract">
                        <span class="abstract-title"><span class="emoji">📝</span>Abstract</span>
                        There is a growing overlap between Machine Learning, Neuroscience, and Network Theory. These three disciplines create a fertile inter-disciplinary cycle: a) inspiration from neuroscience leads to novel machine learning models and deep neural networks in particular, b) these networks can be better understood and designed using network theory, and c) machine learning and network theory provide new modeling tools to understand the brain's structure and function, closing the cycle. In this talk, we will "tour" this cross-disciplinary research agenda by focusing on three recent works: a) the design of sparse neural networks that can learn fast and generalize well, b) the use of structural adaptation (plasticity) for continual learning, and c) the effects of a task's hierarchically modularity on generalization and learning efficiency.
                    </div>
                    <div class="bio">
                        <span class="bio-title"><span class="emoji">👤</span>Bio</span>
                        <div class="speaker-info">
                            <img src="constantine-dovrolis-june2020-face.jpg" alt="Dr. Constantinos Dovrolis" class="speaker-image">
                            <div class="speaker-text">
                                Dr. Constantine Dovrolis is the Director of the center for Computational Science and Technology (CaSToRC) at The Cyprus Institute (CyI) as of 1/1/2023. He is also a Professor at the School of Computer Science at the Georgia Institute of Technology (Georgia Tech). He is a graduate of the Technical University of Crete (Engr.Dipl. 1995), University of Rochester (M.S. 1996), and University of Wisconsin-Madison (Ph.D. 2000).
                                <br>
                                His research is inter-disciplinary, combining Network Theory, Data Mining and Machine Learning. Together with his collaborators and students, they have published in a wide range of scientific disciplines, including climate science, biology, and neuroscience. More recently, his group has been focusing on neuro-inspired architectures for machine learning based on what is currently known about the structure and function of brain networks.
                                <br>
                                According to Google Scholar, his publications have received more than 15,000 citations with an h-index of 56. His research has been sponsored by US agencies such as NSF, NIH, DOE, DARPA, and by companies such as Google, Microsoft and Cisco. He has published at diverse peer-reviewed conferences and journals such as the International Conference on Machine Learning (ICML), the ACM SIGKDD conference, PLOS Computational Biology, Network Neuroscience, Climate Dynamics, the Journal of Computational Social Networks, and others.
                            </div>
                        </div>
                    </div>
                </li>
                <li>
                    <span class="speaker"><span class="emoji">🎤</span><a href="https://yangky11.github.io/" target="_blank">Kaiyu Yang</a></span>
                    <span class="affiliation"><span class="emoji">🏛️</span>Meta Fundamental AI Research (FAIR)</span>
                    <span class="date-time"><span class="emoji">📅</span>Tuesday, April 29th, 2025 | 2:00 PM - 3:00 PM (ET)</span>
                    <span class="location">
                        <span class="emoji">💻</span><a href="https://gatech.zoom.us/j/97783515319?pwd=Ey4DFKBT6OqlakbiP1KVYrGvcOqQdA.1" target="_blank">Zoom</a>
                    </span>
                    <span class="topic"><span class="emoji">📚</span>Talk Title: Formal Reasoning Meets LLMs: Toward AI for Mathematics and Verification</span>
                    <div class="abstract">
                        <span class="abstract-title"><span class="emoji">📝</span>Abstract</span>
                        AI for Mathematics (AI4Math) is intellectually intriguing and crucial for AI-driven system design and verification. Much of the recent progress in this field has paralleled advances in natural language processing, especially by training large language models on curated mathematical text datasets. As a complementary yet less explored avenue, formal mathematical reasoning is grounded in formal systems such as Lean, which can verify the correctness of reasoning and provide automatic feedback. This talk introduces the basics of AI for formal mathematical reasoning, focusing on two central tasks: theorem proving (generating formal proofs given theorem statements) and autoformalization (translating from informal to formal). I will highlight the unique challenges of these tasks through two recent projects: one on proving inequality problems from mathematics olympiads, and another on autoformalizing Euclidean geometry problems.
                    </div>
                    <div class="bio">
                        <span class="bio-title"><span class="emoji">👤</span>Bio</span>
                        <div class="speaker-info">
                            <img src="Kaiyu_Yang.jpg" alt="Dr. Kaiyu Yang" class="speaker-image">
                            <div class="speaker-text">
                                Dr. Kaiyu Yang is a Research Scientist at Meta Fundamental AI Research (FAIR), where he focuses on enhancing AI's capabilities in mathematical reasoning by integrating formal systems such as Lean. His research explores how machine learning and large language models can generate mathematical conjectures, prove theorems, and perform reasoning that combines natural and formal languages. Before joining FAIR, he was a postdoctoral scholar at Caltech. He received a Ph.D. in computer science from Princeton University and bachelor's degrees in computer science and mathematics from Tsinghua University.
                            </div>
                        </div>
                    </div>
                </li>
            </ul>

            <ul>
                <li>
                    <span class="speaker"><span class="emoji">🎤</span><a href="https://www.microsoft.com/en-us/research/people/zorn/" target="_blank">Ben Zorn</a></span>
                    <span class="affiliation"><span class="emoji">🏛️</span>Microsoft Research</span>
                    <span class="date-time"><span class="emoji">📅</span>Thursday, April 17th, 2025 | 3:00 PM - 4:00 PM (ET)</span>
                    <span class="location">
                        <span class="emoji">📍</span>C341 Classroom Van Leer
                    </span>
                    <span class="topic"><span class="emoji">📚</span>Talk Title: Anticipating the Accelerating Growth of AI Software</span>
                    <div class="abstract">
                        <span class="abstract-title"><span class="emoji">📝</span>Abstract</span>
                        Incorporating AI models at runtime into software systems creates "AI Software" (AISW), which is distinct from "Plain Old Software" (POSW) that doesn't use AI models. AISW is fundamentally different from POSW in both capabilities and characteristics. Various names for AISW include copilots, agents, and GPTs, but regardless of the name, AISW has properties that invalidate many traditional software engineering techniques developed for POSW.
                        <br><br>
                        In my talk, I will discuss the growing importance of AISW, its differences from POSW, and the need for the systems community to adapt to this trend. Key differences include the rapid development of new AI models, new operational modalities like vision and audio, larger input contexts, unclear prompt specifications, and diverse failure modes of AI models.
                        <br><br>
                        To make my points concrete, I will focus on two open-source projects I've been involved with: GenAIScript, which is a JavaScript-based scripting language for building AISW applications (<a href="https://microsoft.github.io/genaiscript/" target="_blank">Generative AI Scripting | GenAIScript</a>), and PromptPex, which is a unit test generation tool for testing AI model prompts (<a href="https://github.com/microsoft/promptpex" target="_blank">microsoft/promptpex: Prompt Exploration</a>).
                    </div>
                    <div class="bio">
                        <span class="bio-title"><span class="emoji">👤</span>Bio</span>
                        <div class="speaker-info">
                            <img src="ben.jpg" alt="Dr. Ben Zorn" class="speaker-image">
                            <div class="speaker-text">
                                Ben Zorn is Partner Researcher and former co-manager of the Research in Software Engineering (RiSE) group in Microsoft Research, Redmond WA working on programming languages, software engineering and artificial intelligence. His research interests include usability, security, and reliability, including reliability of artificial intelligence. From 1990-1998 he was an Assistant and Associate Professor of Computer Science at the University of Colorado, Boulder. He has a PhD in computer science from the University of California at Berkeley. Ben has served as the Program Chair and General Chair of PLDI, served on the Executive Committee of SIGPLAN, as a member of the Computing Community Consortium (CCC) Council, is currently a member of the CRA Board of Directors and in 2021 he co-founded the CRA-Industry committee. He is an AAAS Fellow, an ACM Fellow and in 2021 he received the SIGPLAN Distinguished Service Award.
                            </div>
                        </div>
                    </div>
                </li>
                <li>
                    <span class="speaker"><span class="emoji">🎤</span><a href="http://www.cs.ubc.ca/~kevinlb/" target="_blank">Kevin Leyton-Brown</a></span>
                    <span class="affiliation"><span class="emoji">🏛️</span>University of British Columbia</span>
                    <span class="date-time"><span class="emoji">📅</span>Friday, April 4th, 2025 | 4:00 PM - 5:00 PM (ET)</span>
                    <span class="location">
                        <span class="emoji">📍</span>1447 Classroom Klaus
                    </span>
                    <span style="display: block; color: #B3A369; margin-top: 10px;"><span class="emoji">🤝</span>Joint FoAI + ARC + IDEaS Seminar</span>
                    <span style="display: block; color: #666; margin-top: 5px;"><span class="emoji">👥</span>Organizers: Vijay Ganesh, Will Perkins, and Juba Ziani</span>
                    <span class="topic"><span class="emoji">📚</span>Talk Title: STEER: Assessing the Economic Rationality of Large Language Models</span>
                    <div class="abstract">
                        <span class="abstract-title"><span class="emoji">📝</span>Abstract</span>
                        There is increasing interest in using LLMs as decision-making "agents." Doing so includes many degrees of freedom: which model should be used; how should it be prompted; should it be asked to introspect, conduct chain-of-thought reasoning, etc? Settling these questions -- and more broadly, determining whether an LLM agent is reliable enough to be trusted -- requires a methodology for assessing such an agent's economic rationality. This talk describes one. We survey the economic literature on both strategic and non-strategic decision making, taxonomizing 124 fine-grained "elements" that an agent should exhibit, each of which can be tested in up to 3 distinct ways, grounded in up to 10 distinct domains, and phrased according to 5 perspectives (first-person, second-person, etc). The generation of benchmark data across this combinatorial space is powered by a novel LLM-assisted data generation protocol that we dub auto-STEER, which generates questions by adapting handcrafted templates to new domains and perspectives. Because it offers an automated way of generating fresh questions, auto-STEER mitigates the risk that LLMs will be trained to overfit evaluation benchmarks; we thus hope that it will serve as a useful tool both for evaluating and fine-tuning models for years to come. Finally, we describe the results of a large-scale empirical experiment with 28 different LLMs, ranging from small open-source models to the current state of the art. We examined each model's ability to solve problems across our whole taxonomy and present the results across a range of prompting strategies and scoring metrics.
                    </div>
                    <div class="bio">
                        <span class="bio-title"><span class="emoji">👤</span>Bio</span>
                        <div class="speaker-info">
                            <img src="Kevin.jpg" alt="Dr. Kevin Leyton-Brown" class="speaker-image">
                            <div class="speaker-text">
                                Kevin Leyton-Brown is a professor of Computer Science and a Distinguished University Scholar at the University of British Columbia. He holds a Canada CIFAR AI Chair at the Alberta Machine Intelligence Institute and is an associate member of the Vancouver School of Economics. He received a PhD and an M.Sc. from Stanford University (2003; 2001) and a B.Sc. from McMaster University (1998).
                            </div>
                        </div>
                    </div>
                </li>
                <li>
                    <span class="speaker"><span class="emoji">🎤</span><a href="https://www.josecambronero.com/" target="_blank">José Cambronero</a></span>
                    <span class="affiliation"><span class="emoji">🏛️</span>Google</span>
                    <span class="date-time"><span class="emoji">📅</span>Wednesday, April 2nd, 2025 | 3:30 PM - 4:30 PM (ET)</span>
                    <span class="location">
                        <span class="emoji">📍</span>1456 Classroom Klaus
                    </span>
                    <span style="display: block; color: #B3A369; margin-top: 10px;"><span class="emoji">🤝</span>Joint PLSE + FoAI Seminar</span>
                    <span style="display: block; color: #666; margin-top: 5px;"><span class="emoji">👥</span>Organizers: Vijay Ganesh and Alex Orso</span>
                    <span class="topic"><span class="emoji">📚</span>Talk Title: Let the Agent Do It: Fixing, Validating, and Migrating Code at Google with LLM-based Software Agents</span>
                    <div class="abstract">
                        <span class="abstract-title"><span class="emoji">📝</span>Abstract</span>
                        The DevAI team at Google is tasked with developing AI-based features for our internal tools with the goal of making Google software developers more effective and efficient at their jobs. In this talk, I'll provide an overview of some of the unique challenges of applying AI to internal Google developer systems. These challenges motivate the need to build solutions tailored to Google, and I'll present two such LLM-based systems: a program repair agent and a test generation agent, which can respectively patch real Google bugs and generate tests that improve our confidence in these patches. In addition, I will describe broad use cases for AI-based code migration in our codebase. Throughout the talk, I'll focus on some of the open challenges we have faced and how those can inform ongoing research in software engineering and AI.
                    </div>
                    <div class="bio">
                        <span class="bio-title"><span class="emoji">👤</span>Bio</span>
                        <div class="speaker-info">
                            <img src="jose.jpeg" alt="Dr. José Cambronero" class="speaker-image">
                            <div class="speaker-text">
                                José Cambronero is a staff software engineer in Google's DevAI team, where he researches new AI-based solutions to software engineering challenges encountered by Google developers. Prior to joining Google, José was a senior researcher in the PROSE team at Microsoft, working on program synthesis and repair. José holds a PhD in Computer Science from MIT, where he worked under the supervision of Martin Rinard. José is originally from Costa Rica but has bounced around a large portion of the USA's east coast.
                            </div>
                        </div>
                    </div>
                </li>
                <li>
                    <span class="speaker"><span class="emoji">🎤</span><a href="https://mircogiacobbe.github.io/" target="_blank">Mirco Giacobbe</a></span>
                    <span class="affiliation"><span class="emoji">🏛️</span>University of Birmingham</span>
                    <span class="date-time"><span class="emoji">📅</span>Thursday, March 6th, 2025 | 3:30 PM - 4:30 PM (ET)</span>
                    <span class="location">
                        <span class="emoji">📍</span>L5 Classroom Howey Physics
                    </span>
                    <span class="topic"><span class="emoji">📚</span>Talk Title: Neural Model Checking</span>
                    <div class="abstract">
                        <span class="abstract-title"><span class="emoji">📝</span>Abstract</span>
                        Model checking aims to derive rigorous proofs for the correctness of systems and has traditionally relied on symbolic reasoning methods. In this talk, I will argue that model checking can also be effectively addressed using machine learning too. I will present a realm of approaches for formal verification that leverage neural networks to represent correctness certificates of systems, known as "neural certificates." This approach trains certificates from synthetic executions of the system and then validates them using symbolic reasoning techniques. Building upon the observation that checking a correctness certificate is much simpler than finding one, and that neural networks are an appropriate representation for such certificates, this results in a machine learning approach to model checking that is entirely unsupervised, formally sound, and practically effective. I will demonstrate the principles and experimental results of this approach in safety assurance of software, probabilistic systems, and control.
                    </div>
                    <div class="bio">
                        <span class="bio-title"><span class="emoji">👤</span>Bio</span>
                        <div class="speaker-info">
                            <img src="mirco.jpeg" alt="Dr. Mirco Giacobbe" class="speaker-image">
                            <div class="speaker-text">
                                Mirco Giacobbe is an Assistant Professor at the University of Birmingham. He previously held research positions at the University of Oxford and Fondazione Bruno Kessler. He obtained his PhD at the Institute and Science and Technology Austria and studied at the University of Trento and RWTH Aachen. His research interests lie between formal me­thods and artificial intelligence, where he develops automatic techniques to assure that algorithmic systems are safe and trustworthy.
                            </div>
                        </div>
                    </div>
                </li>
                <li>
                    <span class="speaker"><span class="emoji">🎤</span><a href="https://profiles.lbl.gov/88117-aishik-ghosh" target="_blank">Aishik Ghosh</a></span>
                    <span class="affiliation"><span class="emoji">🏛️</span>UC Irvine & Berkeley Lab</span>
                    <span class="date-time"><span class="emoji">📅</span>Wednesday, March 5th, 2025 | 3:30 PM - 4:30 PM (ET)</span>
                    <span class="location">
                        <span class="emoji">📍</span>1456 Classroom Klaus
                    </span>
                    <span class="topic"><span class="emoji">📚</span>Talk Title: Probing High-Dimensional Spaces in Particle Physics: From Simulation-Based Inference to Theory Design</span>
                    <div class="abstract">
                        <span class="abstract-title"><span class="emoji">📝</span>Abstract</span>
                        Particle physicists grapple with the largest data analysis problems, with the Large Hadron Collider soon to generate data at a rate of 100 TB/s. When confronted with extremely high-dimensional problems, physicists traditionally reduce the challenge to a lower dimensional representation where they can build intuition. I will discuss why such dramatic data reduction leads to loss of crucial information, and how neural networks can be combined with uncertainty quantification tools to perform statistical analysis directly using the high-dimensional data. This newly developed method is now being deployed as a service on DOE supercomputers, to usher in an extra of high-dimensional statistical analysis across particle physics experiments.
                        <br><br>
                        Similarly, a significant challenge in theoretical physics is the vast space of mathematical symmetries available to describe our Universe. Despite the dedicated efforts of theorists to explore this expanse, an overwhelming majority remains uncharted. I will discuss an ambitious new research direction in theoretical physics where, in collaboration with researchers at Georgia Tech, we leverage computational and AI tools to uncover new avenues for neutrino theory model building.
                    </div>
                    <div class="bio">
                        <span class="bio-title"><span class="emoji">👤</span>Bio</span>
                        <div class="speaker-info">
                            <img src="aishik.png" alt="Dr. Aishik Ghosh" class="speaker-image">
                            <div class="speaker-text">
                                Dr. Aishik Ghosh is a postdoctoral scholar at UC Irvine and an affiliate at Berkeley Lab, focusing on the development of high-dimensional statistical inference and uncertainty quantification methods using AI for particle and astrophysics. He has papers in physics and astrophysics journals, as well at NeurIPS. He also developed the first deep generative models for fast simulation to be deployed in a particle physics experiment in 2018. Recently, Aishik has been developing advanced symbolic regression and reinforcement learning methods to address challenges in theoretical neutrino physics in an interdisciplinary collaboration with Prof. Vijay Ganesh at Georgia Tech. Previously, he earned his PhD in particle physics from the University of Paris-Saclay.
                            </div>
                        </div>
                    </div>
                </li>
                <li>
                    <span class="speaker"><span class="emoji">🎤</span><a href="https://cs.rice.edu/~xh37/index.html" target="_blank">Xia (Ben) Hu</a></span>
                    <span class="affiliation"><span class="emoji">🏛️</span>Rice University</span>
                    <span class="date-time"><span class="emoji">📅</span>Wednesday, February 12th, 2025 | 12:30 PM - 1:30 PM (ET)</span>
                    <span class="location">
                        <span class="emoji">📍</span>Klaus 1456</a>
                    </span>
                    <span class="topic"><span class="emoji">📚</span>Talk Title: Efficient LLM Serving via Lossy Computation
                </span>
                    <div class="abstract">
                        <span class="abstract-title"><span class="emoji">📝</span>Abstract</span>
                        Large language models (LLMs) have exhibited human-like conversational abilities. Yet, scaling LLMs to longer contexts, such as extracting information from lengthy articles—one of the most fundamental tasks in healthcare applications—poses significant challenges. The primary issues are their inability to handle contexts beyond pre-training lengths and system constraints that make deployment difficult, as memory requirements for inference increase with context length. The key idea to overcome these challenges is that LLMs are extremely robust to noise from lossy computation, such as low-precision computation. Following this insight, we will discuss recent advancements in serving LLMs at scale, particularly in handling longer contexts. To address the algorithmic challenge, I will share our recent work on extending LLM context length to at least 8× longer by coarsening the positional information of distant tokens. To address the system challenge, I will discuss our recent efforts in quantizing the intermediate states of past tokens to 2-bit numbers, leading to a 8x memory efficiency and 3.5x wall-clock time speedup without harming performance. Finally, I will highlight our latest projects applying LLMs in healthcare, particularly how we utilize retrieval techniques for long contexts to mitigate the hallucination problem in healthcare chatbots.
                    </div>
                    <div class="bio">
                        <span class="bio-title"><span class="emoji">👤</span>Bio</span>
                        <div class="speaker-info">
                            <img src="xia_hu.jpg" alt="Dr. Xia (Ben) Hu" class="speaker-image">
                            <div class="speaker-text">
                                Dr. Xia "Ben" Hu is an Associate Professor at Rice University in the Department of Computer Science. Dr. Hu has published over 200 papers in several major academic venues, including NeurIPS, ICLR, ICML, KDD, IJCAI, etc. An open-source package developed by his group, namely AutoKeras, has become the most used automated deep learning system on GitHub (with over 9,000 stars and 1,000 forks). Additionally, his work on LLM efficiency, deep collaborative filtering, anomaly detection, knowledge graphs, and fast interpretation has been incorporated into production systems at Hugging Face, TensorFlow, Apple, Bing, and Meta, respectively. His papers have received several Best Paper (Candidate) awards from venues such as ICML, WWW, WSDM, ICDM, AMIA, and INFORMS. He is the recipient of the NSF CAREER Award and the ACM SIGKDD Rising Star Award. His work has been cited more than 30,000 times with an h-index of 76. He served as General Co-Chair for WSDM 2020 and ICHI 2023, as well as Program Co-Chair for AIHC 2024 and CHASE 2025.
                            </div>
                        </div>
                    </div>
                </li>
                <li>
                    <span class="speaker"><span class="emoji">🎤</span><a href="https://chenwydj.github.io//" target="_blank">Wuyang Chen</a></span>
                    <span class="affiliation"><span class="emoji">🏛️</span>Simon Fraser University</span>
                    <span class="date-time"><span class="emoji">📅</span>Friday, February 7th, 2025 | 4 PM - 5 PM (ET)</span>
                    <span class="location">
                        <span class="emoji">📍</span>Klaus 1447</a> | 
                        <span class="emoji">💻</span><a href="https://gatech.zoom.us/j/96223982260?pwd=vfVZryFICdibBiuGboK0tmRkaiBnV4.1" target="_blank">Zoom</a>
                    </span>
                    <span class="topic"><span class="emoji">📚</span>Talk Title: Scientific Machine Learning in the New Era of AI: Reasoning, Foundations, Visualization
                </span>
                    <div class="abstract">
                        <span class="abstract-title"><span class="emoji">📝</span>Abstract</span>
                        The rapid advancements in artificial intelligence (AI), propelled by data-centric scaling laws, have significantly transformed our understanding and generation of both vision and language. However, natural media, such as images, videos, and languages, represent only a fraction of the modalities we encounter, leaving much of the physical world underexplored. We propose that Scientific Machine Learning (SciML) offers a knowledge-driven framework that complements data-driven AI, enabling us to better understand, visualize, and interact with the diverse complexities of the physical world.
                        <br><br>
                        In this talk, we will delve into the cutting-edge intersection of AI and SciML. First, we will discuss the automation of scientific analysis through multi-step reasoning grounded with formal languages, paving the way for more advanced control and interactions in scientific models. Second, we will explore how scaling scientific data can train foundation models that integrate multiphysics knowledge, thereby enhancing traditional simulations with a deeper understanding of physical principles. Finally, we will demonstrate how SciML can streamline the visualization of intricate geometries, while also showing how spatial intelligence can be adapted for more robust SciML modeling.
                    </div>
                    <div class="bio">
                        <span class="bio-title"><span class="emoji">👤</span>Bio</span>
                        <div class="speaker-info">
                            <img src="wuyang-chen.jpg" alt="Dr. Wuyang Chen" class="speaker-image">
                            <div class="speaker-text">
                                Dr. Wuyang Chen is a tenure-track Assistant Professor in Computing Science at Simon Fraser University. Previously, he was a postdoctoral researcher in Statistics at the University of California, Berkeley. He obtained his Ph.D. in Electrical and Computer Engineering from the University of Texas at Austin in 2023. Dr. Chen's research focuses on scientific machine learning, theoretical understanding of deep networks, and related applications in foundation models, computer vision, and AutoML. He also works on domain adaptation/generalization and self-supervised learning. Dr. Chen has published papers at CVPR, ECCV, ICLR, ICML, NeurIPS, and other top conferences. Dr. Chen's research has been recognized by NSF (National Science Foundation) newsletter in 2022, INNS Doctoral Dissertation Award and the iSchools Doctoral Dissertation Award in 2024, and AAAI New Faculty Highlights in 2025. Dr. Chen is the host of the Foundation Models for Science workshop at NeurIPS 2024 and co-organized the 4th and 5th versions of the UG2+ workshop and challenge at CVPR in 2021 and 2022. He also serves on the board of the One World Seminar Series on the Mathematics of Machine Learning.
                            </div>
                        </div>
                    </div>
                </li>
                <li>
                    <span class="speaker"><span class="emoji">🎤</span><a href="https://www.pmolchanov.com/" target="_blank">Pavlo Molchanov</a></span>
                    <span class="affiliation"><span class="emoji">🏛️</span>NVIDIA Research</span>
                    <span class="date-time"><span class="emoji">📅</span>Thursday, October 10th, 2024 | 12 PM - 1 PM (EDT) </span>
                    <span class="location">
                        <span class="emoji">📍</span><a href="https://maps.app.goo.gl/F2zGTanrUPGp1hTY6" target="_blank">B5 Classroom in Boggs</a> | 
                        <span class="emoji">💻</span><a href="https://gatech.zoom.us/j/92521086871?pwd=KjOr5lQWhjeFKJZxsXfKWd4FOV940m.1" target="_blank">Zoom</a>
                    </span>
                    <span class="topic"><span class="emoji">📚</span>Talk Title: Efficiency in Large Language Models with Post-Training Compression</span>
                    <div class="abstract">
                        <span class="abstract-title"><span class="emoji">📝</span>Abstract</span>
                        Training large language models (LLMs) for various deployment scales and sizes traditionally involves training each variant from scratch, a process that is highly compute-intensive. In this talk, we explore three key techniques to significantly enhance LLM efficiency: (1) pruning and distillation, (2) Flexible LLM architecture with the Many-In-One concept, and (3) an advanced Parameter Efficient Finetuning Technique. Pruning and distillation can reduce pretraining costs by up to 40x, delivering models that are up to 16% more accurate than those trained from scratch. The Flexible LLM architecture allows the transformation of a single LLM into an infinite number of smaller sub-models, streamlining deployment across various applications. Lastly, we will discuss DoRa, a state-of-the-art parameter-efficient fine-tuning method based on weight decomposition, enabling efficient model fine-tuning with limited data.
                    </div>
                    <div class="bio">
                        <span class="bio-title"><span class="emoji">👤</span>Bio</span>
                        <div class="speaker-info">
                            <img src="pavlo.png" alt="Dr. Pavlo Molchanov" class="speaker-image">
                            <div class="speaker-text">
                                Pavlo Molchanov is a Distinguished Research Scientist and Team Manager at <a href="https://research.nvidia.com/home" target="_blank">NVIDIA Research</a>. Since 2023, he has been leading the <a href="https://nv-dler.github.io/" target="_blank">Deep Learning Efficiency Team</a>. He obtained a PhD from Tampere University of Technology, Finland, in 2014. During his studies, he received the Nokia Foundation Scholarship, GETA Graduate School grant, Best Paper Award, and Young Researcher Award at EuRAD. Recently, he has focused on efficiency in LLMs and multi-modal models: compression, NAS-like acceleration, novel architectures, and adaptive/conditional inference. His past research has led to several NVIDIA product integrations: hand, body, and facial keypoint estimation and recognition in <a href="https://blogs.nvidia.com/blog/drive-ix-ecosystem/" target="_blank">DriveIX</a>, <a href="https://www.nvidia.com/en-us/geforce/broadcasting/broadcast-app/?ncid=pa-srch-goog-47075&gad_source=1&gclid=CjwKCAjwjqWzBhAqEiwAQmtgT_gPDTWhu4EQFQg4hmf5OqWMT7zWPvjnPAE7ZkicwT8NAHbT0ITyBBoCgEEQAvD_BwE#cid=gf45_pa-srch-goog_en-us" target="_blank">Broadcast</a>, <a href="https://www.nvidia.com/en-us/omniverse/" target="_blank">Omniverse</a>, <a href="https://developer.nvidia.com/maxine" target="_blank">Maxine</a>; efficient vision backbones in <a href="https://developer.nvidia.com/tao-toolkit" target="_blank">TAO</a>, developed compression techniques in <a href="https://developer.nvidia.com/tao-toolkit" target="_blank">TAO</a>, <a href="https://developer.nvidia.com/drive" target="_blank">NVIDIA AV</a>, <a href="https://github.com/NVIDIA/TensorRT-Model-Optimizer" target="_blank">TRT Model Optimization</a>; and small <a href="https://nvidianews.nvidia.com/news/digital-humans-ace-generative-ai-microservices" target="_blank">in-game LLMs</a>.
                            </div>
                        </div>
                    </div>
                </li>
            </ul>
        </div>

        <div id="mc_embed_signup" class="fade-in">
            <form action="https://google.us22.list-manage.com/subscribe/post?u=95f206f96546b784b621e79fd&amp;id=a4ffd79e69&amp;f_id=004adbe1f0" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank">
                <div id="mc_embed_signup_scroll">
                    <h3>Receive email updates about upcoming talks (for non-SCS members)</h3>
                    <div class="indicates-required"><span class="asterisk">*</span> indicates required</div>
                    <div class="mc-field-group">
                        <label for="mce-EMAIL">Email Address <span class="asterisk">*</span></label>
                        <input type="email" name="EMAIL" class="required email" id="mce-EMAIL" required value="">
                    </div>
                    <div id="mce-responses" class="clear foot">
                        <div class="response" id="mce-error-response" style="display: none;"></div>
                        <div class="response" id="mce-success-response" style="display: none;"></div>
                    </div>
                    <div aria-hidden="true" style="position: absolute; left: -5000px;">
                        <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups -->
                        <input type="text" name="b_95f206f96546b784b621e79fd_a4ffd79e69" tabindex="-1" value="">
                    </div>
                    <div class="optionalParent">
                        <div class="clear foot">
                            <input type="submit" name="subscribe" id="mc-embedded-subscribe" class="button" value="Subscribe">
                        </div>
                    </div>
                </div>
            </form>
        </div>

        <!-- Move the student seminar series link to the end -->
        <a href="students.html" class="student-button fade-in">View Student Speakers</a>
    </div>

    <!-- Add this new section for organizers -->
    <div class="organizers fade-in">
        <h3>Organizers</h3>
        <div class="organizer-grid">
            <div class="organizer">
                <h4>Yingyan (Celine) Lin</h4>
                <p class="title">Associate Professor</p>
                <p><a href="mailto:celine.lin@gatech.edu">celine.lin@gatech.edu</a></p>
                <p><a href="https://eiclab.scs.gatech.edu/" target="_blank">https://eiclab.scs.gatech.edu/</a></p>
                <p class="research-areas">Research Areas: Efficient machine learning through cross-layer innovations</p>
            </div>
            <div class="organizer">
                <h4>Vijay Ganesh</h4>
                <p class="title">Professor</p>
                <p><a href="mailto:vganesh@gatech.edu">vganesh@gatech.edu</a></p>
                <p><a href="https://vganesh1.github.io/" target="_blank">https://vganesh1.github.io/</a></p>
                <p class="research-areas">Research Areas: SAT/SMT solvers, combinations of machine learning and automated reasoning, AI, software engineering, security, combinatorial mathematics, automated scientific discovery</p>
            </div>
        </div>
    </div>

    <script type="text/javascript" src="//s3.amazonaws.com/downloads.mailchimp.com/js/mc-validate.js"></script>
    <script type="text/javascript">
        (function($) {
            window.fnames = new Array();
            window.ftypes = new Array();
            fnames[0]='EMAIL';ftypes[0]='email';fnames[1]='FNAME';ftypes[1]='text';fnames[2]='LNAME';ftypes[2]='text';fnames[3]='ADDRESS';ftypes[3]='address';fnames[4]='PHONE';ftypes[4]='phone';fnames[5]='BIRTHDAY';ftypes[5]='birthday';fnames[6]='COMPANY';ftypes[6]='text';
        }(jQuery));
        var $mcj = jQuery.noConflict(true);
    </script>
    <script>
        function openTab(evt, tabName) {
            var i, tabContent, tabButtons;
            tabContent = document.getElementsByClassName("tab-content");
            for (i = 0; i < tabContent.length; i++) {
                tabContent[i].style.display = "none";
            }
            tabButtons = document.getElementsByClassName("tab-button");
            for (i = 0; i < tabButtons.length; i++) {
                tabButtons[i].className = tabButtons[i].className.replace(" active", "");
            }
            document.getElementById(tabName).style.display = "block";
            evt.currentTarget.className += " active";
        }

        // Add this line to show student speakers by default
        document.getElementById("student-speakers").style.display = "block";
    </script>
</body>
</html>
