<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Foundations of AI Seminar Series | Georgia Tech</title>
    <style>
        body, html {
            margin: 0;
            padding: 0;
            font-family: 'Arial', sans-serif;
            color: #333;
            overflow-x: hidden;
            background-color: white; /* Change background to white */
        }
        .banner {
            width: 100%;
            height: 300px;
            background-image: url('background.jpg'); /* Use background.jpg here */
            background-size: cover;
            background-position: center;
            margin-bottom: 30px;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: rgba(255, 255, 255, 0.8); /* Add semi-transparent white background */
        }
        header {
            text-align: center;
            padding: 50px 0;
        }
        h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            color: #003057;
        }
        h2 {
            font-size: 1.5em;
            color: #B3A369;
            margin-bottom: 20px;
        }
        .intro {
            background-color: rgba(255, 255, 255, 0.8);
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 30px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        .schedule {
            background-color: #f8f8f8;
            padding: 30px;
            border-radius: 15px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        .schedule h3 {
            color: #003057;
            font-size: 2em;
            text-align: center;
            margin-bottom: 30px;
            border-bottom: 2px solid #B3A369;
            padding-bottom: 10px;
        }
        .schedule ul {
            list-style-type: none;
            padding: 0;
        }
        .schedule li {
            background-color: #fff;
            border-radius: 10px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            padding: 25px;
            margin-bottom: 30px;
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }
        .schedule li:hover {
            transform: translateY(-5px);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.15);
        }
        .schedule .speaker,
        .schedule .affiliation,
        .schedule .date-time,
        .schedule .location,
        .schedule .topic {
            font-size: 1.2em;
            margin-bottom: 10px;
            display: block;
        }
        .schedule .speaker {
            font-size: 1.8em;
            font-weight: bold;
            color: #003057;
        }
        .schedule .affiliation {
            color: #666;
            /* Remove the italic style */
            font-style: normal;
        }
        .schedule .date-time,
        .schedule .location {
            background-color: #B3A369;
            color: white;
            padding: 5px 10px;
            border-radius: 5px;
            display: inline-block;
        }
        .schedule .location a {
            color: white;
            text-decoration: none;
            transition: color 0.3s ease;
        }
        .schedule .location a:hover {
            color: #003057;
            text-decoration: underline;
        }
        .schedule .topic {
            font-weight: bold;
            color: #003057;
            margin-top: 15px;
        }
        .schedule .abstract, .schedule .bio {
            margin-top: 20px;
            line-height: 1.6;
            text-align: justify;
        }
        .schedule .abstract-title, .schedule .bio-title {
            font-weight: bold;
            color: #003057;
            margin-bottom: 10px;
            display: block;
            font-size: 1.2em;
            border-bottom: 1px solid #B3A369;
            padding-bottom: 5px;
        }
        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }
        .fade-in {
            animation: fadeIn 1s ease-in;
        }
        #mc_embed_signup {
            background-color: rgba(255, 255, 255, 0.8);
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            margin-top: 30px;
        }
        #mc_embed_signup h3 {
            color: #003057;
            margin-bottom: 20px;
        }
        #mc_embed_signup .mc-field-group {
            margin-bottom: 15px;
        }
        #mc_embed_signup .button {
            background-color: #B3A369;
            color: white;
            border: none;
            padding: 10px 20px;
            border-radius: 5px;
            cursor: pointer;
            transition: background-color 0.3s ease;
        }
        #mc_embed_signup .button:hover {
            background-color: #003057;
        }
        .schedule .emoji {
            margin-right: 10px;
            font-size: 1.2em;
        }
        .organizers {
            background-color: #f8f8f8;
            padding: 30px;
            border-radius: 15px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            margin-top: 30px;
        }

        .organizers h3 {
            color: #003057;
            font-size: 2em;
            text-align: center;
            margin-bottom: 30px;
            border-bottom: 2px solid #B3A369;
            padding-bottom: 10px;
        }

        .organizer-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 30px;
        }

        .organizer {
            background-color: #fff;
            border-radius: 10px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            padding: 25px;
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }

        .organizer:hover {
            transform: translateY(-5px);
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.15);
        }

        .organizer h4 {
            color: #003057;
            font-size: 1.5em;
            margin-bottom: 10px;
        }

        .organizer .title {
            color: #B3A369;
            font-weight: bold;
            margin-bottom: 10px;
        }

        .organizer a {
            color: #003057;
            text-decoration: none;
            transition: color 0.3s ease;
        }

        .organizer a:hover {
            color: #B3A369;
            text-decoration: underline;
        }

        .organizer .research-areas {
            margin-top: 15px;
            font-style: italic;
            color: #666;
        }

        .tabs {
            display: flex;
            justify-content: center;
            margin-bottom: 20px;
        }

        .tab-button {
            background-color: #f1f1f1;
            border: none;
            outline: none;
            cursor: pointer;
            padding: 14px 16px;
            transition: 0.3s;
            font-size: 17px;
            border-radius: 5px 5px 0 0;
            margin: 0 5px;
        }

        .tab-button:hover {
            background-color: #ddd;
        }

        .tab-button.active {
            background-color: #B3A369;
            color: white;
        }

        .tab-content {
            display: none;
            padding: 6px 12px;
            border-top: none;
        }

        .tab-content.active {
            display: block;
        }

        .student-button {
            display: block;
            width: 200px;
            margin: 30px auto;
            padding: 15px 20px;
            background-color: #B3A369;
            color: white;
            text-align: center;
            text-decoration: none;
            font-size: 1.2em;
            border-radius: 5px;
            transition: background-color 0.3s ease;
        }

        .student-button:hover {
            background-color: #003057;
        }

        .sponsorship {
            text-align: center;
            margin-top: 30px;
            padding: 20px;
            background-color: #f8f8f8;
            border-radius: 10px;
        }

        .sponsorship img {
            max-width: 300px; /* Increase the size of the image */
            vertical-align: middle; /* Align the image with the text */
            margin-right: 10px; /* Space between the image and text */
        }

        .sponsorship a {
            color: #003057;
            text-decoration: none;
            transition: color 0.3s ease;
        }

        .sponsorship a:hover {
            color: #B3A369;
            text-decoration: underline;
        }

        .speaker-info {
            display: flex;
            gap: 20px;
            align-items: flex-start;
            margin-top: 20px;
        }

        .speaker-image {
            width: 200px;
            height: 200px;
            object-fit: cover;
            border-radius: 10px;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
        }

        .speaker-text {
            flex: 1;
        }
    </style>
</head>
<body>
    <div class="banner"></div>
    <div class="container">
        <!-- Add the sponsorship section at the top -->
        <div class="sponsorship fade-in">
            <img src="IDEaS.png" alt="IDEaS Logo"> <!-- Include the IDEaS logo -->
            <p>
                Sponsored by <a href="https://research.gatech.edu/energy/ideas" target="_blank">The Institute for Data Engineering and Science (IDEaS)</a>.<br>
                Supported by the <a href="https://www.scs.gatech.edu/" target="_blank">School of Computer Science</a>.
            </p>
        </div>

        <header class="fade-in">
            <h1>Foundations of Artificial Intelligence Seminar Series</h1>
            <h2>by Foundations of Artificial Intelligence @ Georgia Institute of Technology</h2>
        </header>
        <div class="intro fade-in">
            <p>Welcome to the AI Seminar Series @ Georgia Tech, a seminar showcasing the latest research and developments in Artificial Intelligence. Our goal is to bring together students, postdocs, professors, and industry researchers to discuss a wide range of AI topics, including Machine Learning, Efficient AI, Symbolic AI, AI Theory, AI Systems, and the intersection of AI and Programming Languages and Software Engineering (PLSE).</p>
        </div>

        <div class="schedule fade-in">
            <h3>Speaker Schedule and Abstracts</h3>
            
            <h4 style="color: #003057; margin: 30px 0 20px;">Future Talks</h4>
            <ul>
                <li>
                    <span class="speaker"><span class="emoji">🎤</span><a href="https://www.josecambronero.com/" target="_blank">José Cambronero</a></span>
                    <span class="affiliation"><span class="emoji">🏛️</span>Google</span>
                    <span class="date-time"><span class="emoji">📅</span>Wednesday, April 2nd, 2024 | 3:30 PM - 4:30 PM (ET)</span>
                    <span class="location">
                        <span class="emoji">📍</span>1456 Classroom Klaus
                    </span>
                    <span style="display: block; color: #B3A369; margin-top: 10px;"><span class="emoji">🤝</span>Joint PLSE + FoAI Seminar</span>
                    <span style="display: block; color: #666; margin-top: 5px;"><span class="emoji">👥</span>Organizers: Vijay Ganesh and Alex Orso</span>
                    <span class="topic"><span class="emoji">📚</span>Talk Title: Let the Agent Do It: Fixing, Validating, and Migrating Code at Google with LLM-based Software Agents</span>
                    <div class="abstract">
                        <span class="abstract-title"><span class="emoji">📝</span>Abstract</span>
                        The DevAI team at Google is tasked with developing AI-based features for our internal tools with the goal of making Google software developers more effective and efficient at their jobs. In this talk, I'll provide an overview of some of the unique challenges of applying AI to internal Google developer systems. These challenges motivate the need to build solutions tailored to Google, and I'll present two such LLM-based systems: a program repair agent and a test generation agent, which can respectively patch real Google bugs and generate tests that improve our confidence in these patches. In addition, I will describe broad use cases for AI-based code migration in our codebase. Throughout the talk, I'll focus on some of the open challenges we have faced and how those can inform ongoing research in software engineering and AI.
                    </div>
                    <div class="bio">
                        <span class="bio-title"><span class="emoji">👤</span>Bio</span>
                        <div class="speaker-info">
                            <img src="jose.jpeg" alt="Dr. José Cambronero" class="speaker-image">
                            <div class="speaker-text">
                                José Cambronero is a staff software engineer in Google's DevAI team, where he researches new AI-based solutions to software engineering challenges encountered by Google developers. Prior to joining Google, José was a senior researcher in the PROSE team at Microsoft, working on program synthesis and repair. José holds a PhD in Computer Science from MIT, where he worked under the supervision of Martin Rinard. José is originally from Costa Rica but has bounced around a large portion of the USA's east coast.
                            </div>
                        </div>
                    </div>
                </li>
                <li>
                    <span class="speaker"><span class="emoji">🎤</span><a href="http://www.cs.ubc.ca/~kevinlb/" target="_blank">Kevin Leyton-Brown</a></span>
                    <span class="affiliation"><span class="emoji">🏛️</span>University of British Columbia</span>
                    <span class="date-time"><span class="emoji">📅</span>Friday, April 4th, 2025 | 4:00 PM - 5:00 PM (ET)</span>
                    <span class="location">
                        <span class="emoji">📍</span>1447 Classroom Klaus
                    </span>
                    <span style="display: block; color: #B3A369; margin-top: 10px;"><span class="emoji">🤝</span>Joint FoAI + ARC + IDEaS Seminar</span>
                    <span style="display: block; color: #666; margin-top: 5px;"><span class="emoji">👥</span>Organizers: Vijay Ganesh, Will Perkins, and Juba Ziani</span>
                    <span class="topic"><span class="emoji">📚</span>Talk Title: STEER: Assessing the Economic Rationality of Large Language Models</span>
                    <div class="abstract">
                        <span class="abstract-title"><span class="emoji">📝</span>Abstract</span>
                        There is increasing interest in using LLMs as decision-making "agents." Doing so includes many degrees of freedom: which model should be used; how should it be prompted; should it be asked to introspect, conduct chain-of-thought reasoning, etc? Settling these questions -- and more broadly, determining whether an LLM agent is reliable enough to be trusted -- requires a methodology for assessing such an agent's economic rationality. This talk describes one. We survey the economic literature on both strategic and non-strategic decision making, taxonomizing 124 fine-grained "elements" that an agent should exhibit, each of which can be tested in up to 3 distinct ways, grounded in up to 10 distinct domains, and phrased according to 5 perspectives (first-person, second-person, etc). The generation of benchmark data across this combinatorial space is powered by a novel LLM-assisted data generation protocol that we dub auto-STEER, which generates questions by adapting handcrafted templates to new domains and perspectives. Because it offers an automated way of generating fresh questions, auto-STEER mitigates the risk that LLMs will be trained to overfit evaluation benchmarks; we thus hope that it will serve as a useful tool both for evaluating and fine-tuning models for years to come. Finally, we describe the results of a large-scale empirical experiment with 28 different LLMs, ranging from small open-source models to the current state of the art. We examined each model's ability to solve problems across our whole taxonomy and present the results across a range of prompting strategies and scoring metrics.
                    </div>
                    <div class="bio">
                        <span class="bio-title"><span class="emoji">👤</span>Bio</span>
                        <div class="speaker-info">
                            <img src="Kevin.jpg" alt="Dr. Kevin Leyton-Brown" class="speaker-image">
                            <div class="speaker-text">
                                Kevin Leyton-Brown is a professor of Computer Science and a Distinguished University Scholar at the University of British Columbia. He holds a Canada CIFAR AI Chair at the Alberta Machine Intelligence Institute and is an associate member of the Vancouver School of Economics. He received a PhD and an M.Sc. from Stanford University (2003; 2001) and a B.Sc. from McMaster University (1998).
                            </div>
                        </div>
                    </div>
                </li>
            </ul>

            <h4 style="color: #003057; margin: 30px 0 20px;">Past Talks</h4>
            <ul>
                <li>
                    <span class="speaker"><span class="emoji">🎤</span><a href="https://mircogiacobbe.github.io/" target="_blank">Mirco Giacobbe</a></span>
                    <span class="affiliation"><span class="emoji">🏛️</span>University of Birmingham</span>
                    <span class="date-time"><span class="emoji">📅</span>Thursday, March 6th, 2024 | 3:30 PM - 4:30 PM (ET)</span>
                    <span class="location">
                        <span class="emoji">📍</span>L5 Classroom Howey Physics
                    </span>
                    <span class="topic"><span class="emoji">📚</span>Talk Title: Neural Model Checking</span>
                    <div class="abstract">
                        <span class="abstract-title"><span class="emoji">📝</span>Abstract</span>
                        Model checking aims to derive rigorous proofs for the correctness of systems and has traditionally relied on symbolic reasoning methods. In this talk, I will argue that model checking can also be effectively addressed using machine learning too. I will present a realm of approaches for formal verification that leverage neural networks to represent correctness certificates of systems, known as "neural certificates." This approach trains certificates from synthetic executions of the system and then validates them using symbolic reasoning techniques. Building upon the observation that checking a correctness certificate is much simpler than finding one, and that neural networks are an appropriate representation for such certificates, this results in a machine learning approach to model checking that is entirely unsupervised, formally sound, and practically effective. I will demonstrate the principles and experimental results of this approach in safety assurance of software, probabilistic systems, and control.
                    </div>
                    <div class="bio">
                        <span class="bio-title"><span class="emoji">👤</span>Bio</span>
                        <div class="speaker-info">
                            <img src="mirco.jpeg" alt="Dr. Mirco Giacobbe" class="speaker-image">
                            <div class="speaker-text">
                                Mirco Giacobbe is an Assistant Professor at the University of Birmingham. He previously held research positions at the University of Oxford and Fondazione Bruno Kessler. He obtained his PhD at the Institute and Science and Technology Austria and studied at the University of Trento and RWTH Aachen. His research interests lie between formal me­thods and artificial intelligence, where he develops automatic techniques to assure that algorithmic systems are safe and trustworthy.
                            </div>
                        </div>
                    </div>
                </li>
                <li>
                    <span class="speaker"><span class="emoji">🎤</span><a href="https://profiles.lbl.gov/88117-aishik-ghosh" target="_blank">Aishik Ghosh</a></span>
                    <span class="affiliation"><span class="emoji">🏛️</span>UC Irvine & Berkeley Lab</span>
                    <span class="date-time"><span class="emoji">📅</span>Wednesday, March 5th, 2024 | 3:30 PM - 4:30 PM (ET)</span>
                    <span class="location">
                        <span class="emoji">📍</span>1456 Classroom Klaus
                    </span>
                    <span class="topic"><span class="emoji">📚</span>Talk Title: Probing High-Dimensional Spaces in Particle Physics: From Simulation-Based Inference to Theory Design</span>
                    <div class="abstract">
                        <span class="abstract-title"><span class="emoji">📝</span>Abstract</span>
                        Particle physicists grapple with the largest data analysis problems, with the Large Hadron Collider soon to generate data at a rate of 100 TB/s. When confronted with extremely high-dimensional problems, physicists traditionally reduce the challenge to a lower dimensional representation where they can build intuition. I will discuss why such dramatic data reduction leads to loss of crucial information, and how neural networks can be combined with uncertainty quantification tools to perform statistical analysis directly using the high-dimensional data. This newly developed method is now being deployed as a service on DOE supercomputers, to usher in an extra of high-dimensional statistical analysis across particle physics experiments.
                        <br><br>
                        Similarly, a significant challenge in theoretical physics is the vast space of mathematical symmetries available to describe our Universe. Despite the dedicated efforts of theorists to explore this expanse, an overwhelming majority remains uncharted. I will discuss an ambitious new research direction in theoretical physics where, in collaboration with researchers at Georgia Tech, we leverage computational and AI tools to uncover new avenues for neutrino theory model building.
                    </div>
                    <div class="bio">
                        <span class="bio-title"><span class="emoji">👤</span>Bio</span>
                        <div class="speaker-info">
                            <img src="aishik.png" alt="Dr. Aishik Ghosh" class="speaker-image">
                            <div class="speaker-text">
                                Dr. Aishik Ghosh is a postdoctoral scholar at UC Irvine and an affiliate at Berkeley Lab, focusing on the development of high-dimensional statistical inference and uncertainty quantification methods using AI for particle and astrophysics. He has papers in physics and astrophysics journals, as well at NeurIPS. He also developed the first deep generative models for fast simulation to be deployed in a particle physics experiment in 2018. Recently, Aishik has been developing advanced symbolic regression and reinforcement learning methods to address challenges in theoretical neutrino physics in an interdisciplinary collaboration with Prof. Vijay Ganesh at Georgia Tech. Previously, he earned his PhD in particle physics from the University of Paris-Saclay.
                            </div>
                        </div>
                    </div>
                </li>
                <li>
                    <span class="speaker"><span class="emoji">🎤</span><a href="https://cs.rice.edu/~xh37/index.html" target="_blank">Xia (Ben) Hu</a></span>
                    <span class="affiliation"><span class="emoji">🏛️</span>Rice University</span>
                    <span class="date-time"><span class="emoji">📅</span>Wednesday, February 12th, 2025 | 12:30 PM - 1:30 PM (ET)</span>
                    <span class="location">
                        <span class="emoji">📍</span>Klaus 1456</a>
                    </span>
                    <span class="topic"><span class="emoji">📚</span>Talk Title: Efficient LLM Serving via Lossy Computation
                </span>
                    <div class="abstract">
                        <span class="abstract-title"><span class="emoji">📝</span>Abstract</span>
                        Large language models (LLMs) have exhibited human-like conversational abilities. Yet, scaling LLMs to longer contexts, such as extracting information from lengthy articles—one of the most fundamental tasks in healthcare applications—poses significant challenges. The primary issues are their inability to handle contexts beyond pre-training lengths and system constraints that make deployment difficult, as memory requirements for inference increase with context length. The key idea to overcome these challenges is that LLMs are extremely robust to noise from lossy computation, such as low-precision computation. Following this insight, we will discuss recent advancements in serving LLMs at scale, particularly in handling longer contexts. To address the algorithmic challenge, I will share our recent work on extending LLM context length to at least 8× longer by coarsening the positional information of distant tokens. To address the system challenge, I will discuss our recent efforts in quantizing the intermediate states of past tokens to 2-bit numbers, leading to a 8x memory efficiency and 3.5x wall-clock time speedup without harming performance. Finally, I will highlight our latest projects applying LLMs in healthcare, particularly how we utilize retrieval techniques for long contexts to mitigate the hallucination problem in healthcare chatbots.
                    </div>
                    <div class="bio">
                        <span class="bio-title"><span class="emoji">👤</span>Bio</span>
                        <div class="speaker-info">
                            <img src="xia_hu.jpg" alt="Dr. Xia (Ben) Hu" class="speaker-image">
                            <div class="speaker-text">
                                Dr. Xia "Ben" Hu is an Associate Professor at Rice University in the Department of Computer Science. Dr. Hu has published over 200 papers in several major academic venues, including NeurIPS, ICLR, ICML, KDD, IJCAI, etc. An open-source package developed by his group, namely AutoKeras, has become the most used automated deep learning system on GitHub (with over 9,000 stars and 1,000 forks). Additionally, his work on LLM efficiency, deep collaborative filtering, anomaly detection, knowledge graphs, and fast interpretation has been incorporated into production systems at Hugging Face, TensorFlow, Apple, Bing, and Meta, respectively. His papers have received several Best Paper (Candidate) awards from venues such as ICML, WWW, WSDM, ICDM, AMIA, and INFORMS. He is the recipient of the NSF CAREER Award and the ACM SIGKDD Rising Star Award. His work has been cited more than 30,000 times with an h-index of 76. He served as General Co-Chair for WSDM 2020 and ICHI 2023, as well as Program Co-Chair for AIHC 2024 and CHASE 2025.
                            </div>
                        </div>
                    </div>
                </li>
                <li>
                    <span class="speaker"><span class="emoji">🎤</span><a href="https://chenwydj.github.io//" target="_blank">Wuyang Chen</a></span>
                    <span class="affiliation"><span class="emoji">🏛️</span>Simon Fraser University</span>
                    <span class="date-time"><span class="emoji">📅</span>Friday, February 7th, 2025 | 4 PM - 5 PM (ET)</span>
                    <span class="location">
                        <span class="emoji">📍</span>Klaus 1447</a> | 
                        <span class="emoji">💻</span><a href="https://gatech.zoom.us/j/96223982260?pwd=vfVZryFICdibBiuGboK0tmRkaiBnV4.1" target="_blank">Zoom</a>
                    </span>
                    <span class="topic"><span class="emoji">📚</span>Talk Title: Scientific Machine Learning in the New Era of AI: Reasoning, Foundations, Visualization
                </span>
                    <div class="abstract">
                        <span class="abstract-title"><span class="emoji">📝</span>Abstract</span>
                        The rapid advancements in artificial intelligence (AI), propelled by data-centric scaling laws, have significantly transformed our understanding and generation of both vision and language. However, natural media, such as images, videos, and languages, represent only a fraction of the modalities we encounter, leaving much of the physical world underexplored. We propose that Scientific Machine Learning (SciML) offers a knowledge-driven framework that complements data-driven AI, enabling us to better understand, visualize, and interact with the diverse complexities of the physical world.
                        <br><br>
                        In this talk, we will delve into the cutting-edge intersection of AI and SciML. First, we will discuss the automation of scientific analysis through multi-step reasoning grounded with formal languages, paving the way for more advanced control and interactions in scientific models. Second, we will explore how scaling scientific data can train foundation models that integrate multiphysics knowledge, thereby enhancing traditional simulations with a deeper understanding of physical principles. Finally, we will demonstrate how SciML can streamline the visualization of intricate geometries, while also showing how spatial intelligence can be adapted for more robust SciML modeling.
                    </div>
                    <div class="bio">
                        <span class="bio-title"><span class="emoji">👤</span>Bio</span>
                        <div class="speaker-info">
                            <img src="wuyang-chen.jpg" alt="Dr. Wuyang Chen" class="speaker-image">
                            <div class="speaker-text">
                                Dr. Wuyang Chen is a tenure-track Assistant Professor in Computing Science at Simon Fraser University. Previously, he was a postdoctoral researcher in Statistics at the University of California, Berkeley. He obtained his Ph.D. in Electrical and Computer Engineering from the University of Texas at Austin in 2023. Dr. Chen's research focuses on scientific machine learning, theoretical understanding of deep networks, and related applications in foundation models, computer vision, and AutoML. He also works on domain adaptation/generalization and self-supervised learning. Dr. Chen has published papers at CVPR, ECCV, ICLR, ICML, NeurIPS, and other top conferences. Dr. Chen's research has been recognized by NSF (National Science Foundation) newsletter in 2022, INNS Doctoral Dissertation Award and the iSchools Doctoral Dissertation Award in 2024, and AAAI New Faculty Highlights in 2025. Dr. Chen is the host of the Foundation Models for Science workshop at NeurIPS 2024 and co-organized the 4th and 5th versions of the UG2+ workshop and challenge at CVPR in 2021 and 2022. He also serves on the board of the One World Seminar Series on the Mathematics of Machine Learning.
                            </div>
                        </div>
                    </div>
                </li>
                <li>
                    <span class="speaker"><span class="emoji">🎤</span><a href="https://www.pmolchanov.com/" target="_blank">Pavlo Molchanov</a></span>
                    <span class="affiliation"><span class="emoji">🏛️</span>NVIDIA Research</span>
                    <span class="date-time"><span class="emoji">📅</span>Thursday, October 10th, 2024 | 12 PM - 1 PM (EDT) </span>
                    <span class="location">
                        <span class="emoji">📍</span><a href="https://maps.app.goo.gl/F2zGTanrUPGp1hTY6" target="_blank">B5 Classroom in Boggs</a> | 
                        <span class="emoji">💻</span><a href="https://gatech.zoom.us/j/92521086871?pwd=KjOr5lQWhjeFKJZxsXfKWd4FOV940m.1" target="_blank">Zoom</a>
                    </span>
                    <span class="topic"><span class="emoji">📚</span>Talk Title: Efficiency in Large Language Models with Post-Training Compression</span>
                    <div class="abstract">
                        <span class="abstract-title"><span class="emoji">📝</span>Abstract</span>
                        Training large language models (LLMs) for various deployment scales and sizes traditionally involves training each variant from scratch, a process that is highly compute-intensive. In this talk, we explore three key techniques to significantly enhance LLM efficiency: (1) pruning and distillation, (2) Flexible LLM architecture with the Many-In-One concept, and (3) an advanced Parameter Efficient Finetuning Technique. Pruning and distillation can reduce pretraining costs by up to 40x, delivering models that are up to 16% more accurate than those trained from scratch. The Flexible LLM architecture allows the transformation of a single LLM into an infinite number of smaller sub-models, streamlining deployment across various applications. Lastly, we will discuss DoRa, a state-of-the-art parameter-efficient fine-tuning method based on weight decomposition, enabling efficient model fine-tuning with limited data.
                    </div>
                    <div class="bio">
                        <span class="bio-title"><span class="emoji">👤</span>Bio</span>
                        <div class="speaker-info">
                            <img src="pavlo.png" alt="Dr. Pavlo Molchanov" class="speaker-image">
                            <div class="speaker-text">
                                Pavlo Molchanov is a Distinguished Research Scientist and Team Manager at <a href="https://research.nvidia.com/home" target="_blank">NVIDIA Research</a>. Since 2023, he has been leading the <a href="https://nv-dler.github.io/" target="_blank">Deep Learning Efficiency Team</a>. He obtained a PhD from Tampere University of Technology, Finland, in 2014. During his studies, he received the Nokia Foundation Scholarship, GETA Graduate School grant, Best Paper Award, and Young Researcher Award at EuRAD. Recently, he has focused on efficiency in LLMs and multi-modal models: compression, NAS-like acceleration, novel architectures, and adaptive/conditional inference. His past research has led to several NVIDIA product integrations: hand, body, and facial keypoint estimation and recognition in <a href="https://blogs.nvidia.com/blog/drive-ix-ecosystem/" target="_blank">DriveIX</a>, <a href="https://www.nvidia.com/en-us/geforce/broadcasting/broadcast-app/?ncid=pa-srch-goog-47075&gad_source=1&gclid=CjwKCAjwjqWzBhAqEiwAQmtgT_gPDTWhu4EQFQg4hmf5OqWMT7zWPvjnPAE7ZkicwT8NAHbT0ITyBBoCgEEQAvD_BwE#cid=gf45_pa-srch-goog_en-us" target="_blank">Broadcast</a>, <a href="https://www.nvidia.com/en-us/omniverse/" target="_blank">Omniverse</a>, <a href="https://developer.nvidia.com/maxine" target="_blank">Maxine</a>; efficient vision backbones in <a href="https://developer.nvidia.com/tao-toolkit" target="_blank">TAO</a>, developed compression techniques in <a href="https://developer.nvidia.com/tao-toolkit" target="_blank">TAO</a>, <a href="https://developer.nvidia.com/drive" target="_blank">NVIDIA AV</a>, <a href="https://github.com/NVIDIA/TensorRT-Model-Optimizer" target="_blank">TRT Model Optimization</a>; and small <a href="https://nvidianews.nvidia.com/news/digital-humans-ace-generative-ai-microservices" target="_blank">in-game LLMs</a>.
                            </div>
                        </div>
                    </div>
                </li>
            </ul>
        </div>

        <div id="mc_embed_signup" class="fade-in">
            <form action="https://google.us22.list-manage.com/subscribe/post?u=95f206f96546b784b621e79fd&amp;id=a4ffd79e69&amp;f_id=004adbe1f0" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank">
                <div id="mc_embed_signup_scroll">
                    <h3>Receive email updates about upcoming talks (for non-SCS members)</h3>
                    <div class="indicates-required"><span class="asterisk">*</span> indicates required</div>
                    <div class="mc-field-group">
                        <label for="mce-EMAIL">Email Address <span class="asterisk">*</span></label>
                        <input type="email" name="EMAIL" class="required email" id="mce-EMAIL" required value="">
                    </div>
                    <div id="mce-responses" class="clear foot">
                        <div class="response" id="mce-error-response" style="display: none;"></div>
                        <div class="response" id="mce-success-response" style="display: none;"></div>
                    </div>
                    <div aria-hidden="true" style="position: absolute; left: -5000px;">
                        <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups -->
                        <input type="text" name="b_95f206f96546b784b621e79fd_a4ffd79e69" tabindex="-1" value="">
                    </div>
                    <div class="optionalParent">
                        <div class="clear foot">
                            <input type="submit" name="subscribe" id="mc-embedded-subscribe" class="button" value="Subscribe">
                        </div>
                    </div>
                </div>
            </form>
        </div>

        <!-- Move the student seminar series link to the end -->
        <a href="students.html" class="student-button fade-in">View Student Speakers</a>
    </div>

    <!-- Add this new section for organizers -->
    <div class="organizers fade-in">
        <h3>Organizers</h3>
        <div class="organizer-grid">
            <div class="organizer">
                <h4>Yingyan (Celine) Lin</h4>
                <p class="title">Associate Professor</p>
                <p><a href="mailto:celine.lin@gatech.edu">celine.lin@gatech.edu</a></p>
                <p><a href="https://eiclab.scs.gatech.edu/" target="_blank">https://eiclab.scs.gatech.edu/</a></p>
                <p class="research-areas">Research Areas: Efficient machine learning through cross-layer innovations</p>
            </div>
            <div class="organizer">
                <h4>Vijay Ganesh</h4>
                <p class="title">Professor</p>
                <p><a href="mailto:vganesh@gatech.edu">vganesh@gatech.edu</a></p>
                <p><a href="https://vganesh1.github.io/" target="_blank">https://vganesh1.github.io/</a></p>
                <p class="research-areas">Research Areas: SAT/SMT solvers, combinations of machine learning and automated reasoning, AI, software engineering, security, combinatorial mathematics, automated scientific discovery</p>
            </div>
        </div>
    </div>

    <script type="text/javascript" src="//s3.amazonaws.com/downloads.mailchimp.com/js/mc-validate.js"></script>
    <script type="text/javascript">
        (function($) {
            window.fnames = new Array();
            window.ftypes = new Array();
            fnames[0]='EMAIL';ftypes[0]='email';fnames[1]='FNAME';ftypes[1]='text';fnames[2]='LNAME';ftypes[2]='text';fnames[3]='ADDRESS';ftypes[3]='address';fnames[4]='PHONE';ftypes[4]='phone';fnames[5]='BIRTHDAY';ftypes[5]='birthday';fnames[6]='COMPANY';ftypes[6]='text';
        }(jQuery));
        var $mcj = jQuery.noConflict(true);
    </script>
    <script>
        function openTab(evt, tabName) {
            var i, tabContent, tabButtons;
            tabContent = document.getElementsByClassName("tab-content");
            for (i = 0; i < tabContent.length; i++) {
                tabContent[i].style.display = "none";
            }
            tabButtons = document.getElementsByClassName("tab-button");
            for (i = 0; i < tabButtons.length; i++) {
                tabButtons[i].className = tabButtons[i].className.replace(" active", "");
            }
            document.getElementById(tabName).style.display = "block";
            evt.currentTarget.className += " active";
        }

        // Add this line to show student speakers by default
        document.getElementById("student-speakers").style.display = "block";
    </script>
</body>
</html>
